{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Cifar-10 model steal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPijn6KdxNns3N92QC63O2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abijith007/Bosch/blob/main/Cifar_10_model_steal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYnwsC9-jzVG"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils \n",
        "from keras import backend as K \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXwkHKhRj_eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf16b12-76ef-48b4-a4d3-ab2160e34b11"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "# let's load data \n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ4GOVfTj_o3"
      },
      "source": [
        "#normalizing inputs from 0-255 to 0.0-1.0 \n",
        "X_train = X_train.astype('float32') \n",
        "X_test = X_test.astype('float32') \n",
        "X_train = X_train / 255.0 \n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6yUpIdmj_rf"
      },
      "source": [
        "# one hot encode outputs \n",
        "y_train = np_utils.to_categorical(y_train) \n",
        "y_test = np_utils.to_categorical(y_test) \n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XaFjgwjj_tq"
      },
      "source": [
        "# Create the model \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model.add(Flatten()) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrhGuK0fmTgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356b807a-9891-4e99-844d-a9b7839c8679"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqRL5OHomTjX"
      },
      "source": [
        "# Compile model \n",
        "lrate = 0.01 \n",
        "epochs = 100\n",
        "decay = lrate/epochs \n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False) \n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "vW3MxmMUmTlx",
        "outputId": "3ac6ecc3-05e2-453f-ee0b-3cb87870b763"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32) \n",
        "# Final evaluation of the model \n",
        "scores = model.evaluate(X_test, y_test, verbose=1) \n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 478s 305ms/step - loss: 2.0420 - accuracy: 0.2370 - val_loss: 1.4844 - val_accuracy: 0.4392\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 476s 305ms/step - loss: 1.4618 - accuracy: 0.4649 - val_loss: 1.2355 - val_accuracy: 0.5576\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 475s 304ms/step - loss: 1.2279 - accuracy: 0.5543 - val_loss: 1.0449 - val_accuracy: 0.6281\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 473s 303ms/step - loss: 1.0540 - accuracy: 0.6272 - val_loss: 0.9884 - val_accuracy: 0.6560\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 475s 304ms/step - loss: 0.8971 - accuracy: 0.6825 - val_loss: 0.8625 - val_accuracy: 0.6935\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 480s 307ms/step - loss: 0.8032 - accuracy: 0.7174 - val_loss: 0.7745 - val_accuracy: 0.7316\n",
            "Epoch 7/100\n",
            "1351/1563 [========================>.....] - ETA: 1:02 - loss: 0.7135 - accuracy: 0.7471"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b223cec4842d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_zF6xAo3umD"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "actual = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  test_image =np.expand_dims(X_test[i], axis =0) \n",
        "  result = model.predict(test_image).argmax() \n",
        "  if result==0: \n",
        "      actual.append(\"Aeroplane\") \n",
        "  elif result==1: \n",
        "      actual.append('Automobile') \n",
        "  elif result==2: \n",
        "      actual.append('Bird') \n",
        "  elif result==3: \n",
        "      actual.append('Cat') \n",
        "  elif result==4: \n",
        "      actual.append('Deer') \n",
        "  elif result==5: \n",
        "      actual.append('Dog') \n",
        "  elif result==6: \n",
        "      actual.append('Frog') \n",
        "  elif result==7: \n",
        "      actual.append('Horse') \n",
        "  elif result==8: \n",
        "      actual.append('Ship') \n",
        "  elif result==9: \n",
        "      actual.append('Truck') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(actual,y_test[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5r6eX9e7K6i"
      },
      "source": [
        "predicted = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i].argmax()==0: \n",
        "      predicted.append(\"Aeroplane\") \n",
        "  elif y_test[i].argmax()==1: \n",
        "      predicted.append('Automobile') \n",
        "  elif y_test[i].argmax()==2: \n",
        "      predicted.append('Bird') \n",
        "  elif y_test[i].argmax()==3: \n",
        "      predicted.append('Cat') \n",
        "  elif y_test[i].argmax()==4: \n",
        "      predicted.append('Deer') \n",
        "  elif y_test[i].argmax()==5: \n",
        "      predicted.append('Dog') \n",
        "  elif y_test[i].argmax()==6: \n",
        "      predicted.append('Frog') \n",
        "  elif y_test[i].argmax()==7: \n",
        "      predicted.append('Horse') \n",
        "  elif y_test[i].argmax()==8: \n",
        "      predicted.append('Ship') \n",
        "  elif y_test[i].argmax()==9: \n",
        "      predicted.append('Truck') \n",
        "\n",
        "\n",
        "print(len(actual),len(predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeIRBPc1pGI"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {'y_Actual':    actual,\n",
        "        'y_Predicted': predicted\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))  \n",
        "sn.heatmap(confusion_matrix, annot=True, linewidths=1.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpT6vQvQ-TYz"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Aeroplane', 'Automobile', 'Bird','Cat','Deer','Dog', 'Frog','Horse', 'Ship', 'Truck']\n",
        "print(classification_report(actual, predicted, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4hJvFsM3GNW"
      },
      "source": [
        "from keras.models import load_model \n",
        "model.save('cifar-10_original_model.h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4joQ9m-z3GP0",
        "outputId": "45f28020-ef6f-4dd1-962c-28a876d860de"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('cifar-10_original_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplqefjv5d/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ars7Sv323jHQ",
        "outputId": "a3a1bea1-c090-41d8-eb55-b8e44f75bd31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgvh0OxV9zLy",
        "outputId": "96439bb3-0b43-4e4c-a051-ca524e6fa430"
      },
      "source": [
        "#!ls drive/MyDrive/Bosch\n",
        "#!cp cifar-10_original_model.h5 drive/MyDrive/Bosch/\n",
        "#!cp cifar-10_original_model.tflite drive/MyDrive/Bosch/\n",
        "#!ls drive/MyDrive/Bosch"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Bosch Report - 01-04-2021.docx'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqsgfauI32ao"
      },
      "source": [
        "##**Model steal**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ta3QTK7aSK"
      },
      "source": [
        "Label generation of noisy input using original model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yCa0Odo30jY"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtxRZ65h4fpx"
      },
      "source": [
        "def noisy(noise_typ,image):\n",
        "   if noise_typ == \"gauss\":\n",
        "      row,col,ch= image.shape\n",
        "      mean = 0\n",
        "      var = 0.1\n",
        "      sigma = var**0.5\n",
        "      gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
        "      gauss = gauss.reshape(row,col,ch)\n",
        "      noisy = image + gauss\n",
        "      return noisy\n",
        "   elif noise_typ == \"s&p\":\n",
        "      row,col,ch = image.shape\n",
        "      s_vs_p = 0.5\n",
        "      amount = 0.7\n",
        "      out = np.copy(image)\n",
        "      # Salt mode\n",
        "      num_salt = np.ceil(amount * image.size * s_vs_p)\n",
        "      coords = [np.random.randint(0, i - 1, int(num_salt))\n",
        "              for i in image.shape]\n",
        "      out[coords] = np.random.randint(low=0,high=124,size=1)\n",
        "\n",
        "      # Pepper mode\n",
        "      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
        "      coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
        "              for i in image.shape]\n",
        "      out[coords] = np.random.randint(low=124,high=255,size=1)\n",
        "      return out\n",
        "   elif noise_typ == \"poisson\":\n",
        "      vals = len(np.unique(image))\n",
        "      vals = 2 ** np.ceil(np.log2(vals))\n",
        "      noisy = np.random.poisson(image * vals) / float(vals)\n",
        "      return noisy\n",
        "   elif noise_typ ==\"speckle\":\n",
        "      row,col,ch = image.shape\n",
        "      gauss = np.random.randn(row,col,ch)\n",
        "      gauss = gauss.reshape(row,col,ch)        \n",
        "      noisy = image + image * gauss\n",
        "      return noisy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eTs0gg45E_R"
      },
      "source": [
        "(x_train_rLabel, y_train_rLabel), (x_test_rLabel, y_test_rLabel) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqw0zOOv4iLc"
      },
      "source": [
        "percentage = 1\n",
        "num_of_img = int(len(x_train_rLabel)*(percentage/100))\n",
        "x_train_noise = []\n",
        "for i in range(num_of_img):\n",
        "  x_train_noise.append(x_train_rLabel[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC_71vY05YBS"
      },
      "source": [
        "for i in range(num_of_img):\n",
        "  x_train_noise[i] = noisy('s&p',x_train_noise[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcs81H_z5YEA"
      },
      "source": [
        "plt.imshow(x_train_noise[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOoDOL0t5YGW"
      },
      "source": [
        "plt.imshow(x_train_noise[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fBVbxcR5YI1"
      },
      "source": [
        "rLabels = []\n",
        "rLabels.append(model.predict(x_train_noise[0]))\n",
        "print(rLabels)\n",
        "\n",
        "#for i in range(num_of_img):\n",
        "#  rLabels.append(model.predict(x_train_rLabel))\n",
        "#  print(rLabels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNbvCJTZ7gkR"
      },
      "source": [
        "Model training of the generated input with labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3PIt36Y74rG"
      },
      "source": [
        "model_steal = Sequential()\n",
        "model_steal.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same')) \n",
        "model_steal.add(Dropout(0.2)) \n",
        "model_steal.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model_steal.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(Dropout(0.2)) \n",
        "model_steal.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model_steal.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(Dropout(0.2))\n",
        "model_steal.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(Dropout(0.4)) \n",
        "model_steal.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
        "model_steal.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "model_steal.add(Flatten()) \n",
        "model_steal.add(Dropout(0.2)) \n",
        "model_steal.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model_steal.add(Dropout(0.2)) \n",
        "model_steal.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3))) \n",
        "model_steal.add(Dropout(0.2)) \n",
        "model_steal.add(Dense(num_classes, activation='softmax'))\n",
        "print(model_steal.summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTk8tK808Jti"
      },
      "source": [
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "it_train = datagen.flow(x_train_noise, rLabels, batch_size=64)\n",
        "steps = int(x_train.shape[0] / 64)\n",
        "history = model_steal.fit_generator(it_train, steps_per_epoch=steps, epochs=200, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3BNhCSL9FYk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "actual_stolen = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  test_image =np.expand_dims(X_test[i], axis =0) \n",
        "  result = model_steal.predict(test_image).argmax() \n",
        "  if result==0: \n",
        "      actual_stolen.append(\"Aeroplane\") \n",
        "  elif result==1: \n",
        "      actual_stolen.append('Automobile') \n",
        "  elif result==2: \n",
        "      actual_stolen.append('Bird') \n",
        "  elif result==3: \n",
        "      actual_stolen.append('Cat') \n",
        "  elif result==4: \n",
        "      actual_stolen.append('Deer') \n",
        "  elif result==5: \n",
        "      actual_stolen.append('Dog') \n",
        "  elif result==6: \n",
        "      actual_stolen.append('Frog') \n",
        "  elif result==7: \n",
        "      actual_stolen.append('Horse') \n",
        "  elif result==8: \n",
        "      actual_stolen.append('Ship') \n",
        "  elif result==9: \n",
        "      actual_stolen.append('Truck') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(actual_stolen,y_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyd-RRR3LrqL"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = {'y_Actual':    actual,\n",
        "        'y_Predicted': predicted\n",
        "        }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))  \n",
        "sn.heatmap(confusion_matrix, annot=True, linewidths=1.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfb9SqcLrsw"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Aeroplane', 'Automobile', 'Bird','Cat','Deer','Dog', 'Frog','Horse', 'Ship', 'Truck']\n",
        "print(classification_report(actual, predicted, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag8KWqh0LwXP"
      },
      "source": [
        "from keras.models import load_model \n",
        "model.save('cifar-10_stolen_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2-t9JmNL0sy"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('cifar-10_stolenl_model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "122rtkn9L0vd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}