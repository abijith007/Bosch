{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Black box Cifar",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO02Qxp0erG0E/lyIh+PGcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abijith007/Bosch/blob/main/Black_box_Cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLqqP0SW13cA"
      },
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSXbcRZZ2N5h"
      },
      "source": [
        "# Load Data and training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVEE1xR42N8i"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes = 10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHKWbAP2N_C"
      },
      "source": [
        "model = tf.keras.models.load_model(\"cifar.h5\")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvkvtd-j2OBK"
      },
      "source": [
        "pred_test = model.predict(x_test)\n",
        "\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "pred_test = keras.utils.to_categorical(pred_test , num_classes = 10)\n",
        "\n",
        "acc = accuracy_score(y_test, pred_test)\n",
        "\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "y_ori = np.argmax(y_test, axis=-1)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(classification_report(y_ori, pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWui5UFM2ODg"
      },
      "source": [
        "def normalize_attack(X_at,y_at):\n",
        "  y_at_max = np.argmax(y_at,axis=-1)\n",
        "  a = y_at_max.tolist()\n",
        "  unq =np.unique(y_at_max)\n",
        "  # print(unq)\n",
        "  k =0 \n",
        "  minimum =list()\n",
        "  for i in range(len(unq)-1):\n",
        "      # print(unq[i], a.count(unq[i]))\n",
        "      if a.count(unq[i]) !=0:\n",
        "        # if k == 0:\n",
        "        #   minimum = list(a.count(unq[i]))\n",
        "        #   k=k+1\n",
        "        # else:\n",
        "        minimum.append(a.count(unq[i]))\n",
        "  minimum.sort()\n",
        "  # print(minimum)\n",
        "  \n",
        "  sec_min = minimum[1]\n",
        "\n",
        "  for i in range(len(unq)):\n",
        "    if i == 0 :\n",
        "      y_normal =  y_at[np.where(y_at_max==unq[i])[0]][0:sec_min]\n",
        "      X_normal = X_at[np.where(y_at_max==unq[i])[0]][0:sec_min]\n",
        "    else:\n",
        "\n",
        "  \n",
        "      y_normal = np.concatenate((y_normal,y_at[np.where(y_at_max==unq[i])[0]][0:sec_min]),axis=0)\n",
        "      X_normal = np.concatenate((X_normal,X_at[np.where(y_at_max==unq[i])[0]][0:sec_min]),axis=0)\n",
        "\n",
        "  return X_normal,y_normal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfPbBmGq2OFj"
      },
      "source": [
        "# Inception = tf.compat.v1.keras.applications.inception_v3.InceptionV3()\n",
        "# features_list = [layer.output for layer in Inception.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFPDe0ob2OH8"
      },
      "source": [
        "noises= [\"gauss\",\"s&p\",\"speckle\",\"normal\",\"bernolli\",\"poisson\"]\n",
        "noise_exclusive = [\"gauss\",\"s&p\",\"speckle\",\"normal\",\"bernolli\"]\n",
        "# print(features_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjscaU2R6D5t"
      },
      "source": [
        "def evalu_quar(out) :   \n",
        "    a = out.tolist()\n",
        "    unq =np.unique(out)\n",
        "    print(unq)\n",
        "    for i in range(len(unq)):\n",
        "        print(unq[i], a.count(unq[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HAw_u3Z6D8B"
      },
      "source": [
        "# np.random.seed(12)\n",
        "# layers = Inception.get_layer('conv2d_'+str(1_1)).get_weights()\n",
        "\n",
        "# print(layers[0].shape)\n",
        "\n",
        "# np.save(\"layer_o.npy\",layers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_LARUkN6D-c"
      },
      "source": [
        "np.random.seed(12)\n",
        "# layers = Inception.get_layer('conv2d_'+str(1_1)).get_weights()\n",
        "def fil():\n",
        "    \n",
        "    x1w = np.load(\"layer_o.npy\")\n",
        "    np.random.shuffle(x1w)\n",
        "    img = [0,0,0,0,0]\n",
        "    k= 0\n",
        "    for i in range(5):\n",
        "        img[i] = x1w[:,:,:,k]\n",
        "        for j in range(4):\n",
        "            l= k+j\n",
        "            img[i] = np.concatenate((img[i], x1w[:,:,:,l]), axis=0)\n",
        "        k =k+5\n",
        "    img_final = img[0]\n",
        "    for u in range(1,5):\n",
        "        img_final = np.concatenate((img_final, img[u]), axis=1)\n",
        "    return img_final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWmwgn3j6EBF"
      },
      "source": [
        "np.random.seed(12)\n",
        "\n",
        "def noisy(noise_typ,image):\n",
        "    row,col= image.shape    \n",
        "    \n",
        "    if noise_typ == \"gauss\":\n",
        "        row,col= image.shape\n",
        "        mean = np.random.rand()-0.5\n",
        "        var = np.random.rand()\n",
        "        sigma = var**0.5\n",
        "        gauss = np.random.normal(mean,sigma,(row,col))\n",
        "        gauss = gauss.reshape(row,col)\n",
        "        noisy = image + gauss\n",
        "        return noisy \n",
        "    elif noise_typ == \"normal\":\n",
        "        np.random.seed(1234)\n",
        "        mean = np.random.rand()-0.5\n",
        "        var = np.random.rand()\n",
        "        sigma = var**0.5\n",
        "        samples=np.random.lognormal(mean,sigma,(row,col))\n",
        "        samples=samples.reshape(row,col)\n",
        "        noisy = image + samples\n",
        "        return noisy\n",
        "    \n",
        "    elif noise_typ == \"bernolli\":\n",
        "        row,col= image.shape\n",
        "        samples=np.random.binomial(10,0.5,(row,col))\n",
        "        samples=samples.reshape(row,col)\n",
        "        noisy = image + samples\n",
        "        return noisy\n",
        "\n",
        "    elif noise_typ == \"s&p\":\n",
        "        row,col = image.shape\n",
        "        s_vs_p = 0.5\n",
        "        amount = 0.004\n",
        "        out = np.copy(image)\n",
        "        # Salt mode\n",
        "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
        "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
        "              for i in image.shape]\n",
        "        out[coords] = 1\n",
        "\n",
        "        # Pepper mode\n",
        "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
        "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
        "              for i in image.shape]\n",
        "        out[coords] = 0\n",
        "        return out\n",
        "    elif noise_typ == \"poisson\":\n",
        "        # vals = len(np.unique(image))\n",
        "        # vals = 2 ** np.ceil(np.log2(vals))\n",
        "        # noisy = np.random.poisson(image * vals)\n",
        "        PEAK=1\n",
        "        noisy = np.random.poisson(image / 255.0 * PEAK) / PEAK * 255 \n",
        "        \n",
        "        return noisy\n",
        "    elif noise_typ ==\"speckle\":\n",
        "\n",
        "        gauss = np.random.randn(row,col)\n",
        "        gauss = gauss.reshape(row,col)        \n",
        "        noisy = image + image * gauss\n",
        "        return noisy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udv8tbYz6EDy"
      },
      "source": [
        "np.random.seed(12)\n",
        "\n",
        "def random_square(img,x,y,max_height_x,max_height_y ):\n",
        "\n",
        "    box = np.array([np.random.randint(0,255)]*max_height_x*max_height_y).reshape(max_height_x,max_height_y)\n",
        "    try: \n",
        "        \n",
        "        img[x:x+max_height_x, y:y+max_height_y] = box\n",
        "    except:\n",
        "        pass\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qU9k_0w6EGN"
      },
      "source": [
        "np.random.seed(12)\n",
        "\n",
        "def query(number_attack_vector):\n",
        "    FLAG =0\n",
        "    attack_data = np.random.random((100000,32,32,3))\n",
        "\n",
        "    y_pred = []\n",
        "    dim = 32\n",
        "    l =np.random.randint(0,10)\n",
        "    image_noise = np.random.randint(0,5)\n",
        "    k =0\n",
        "    for t in tqdm(range(number_attack_vector)):\n",
        "     \n",
        "        \n",
        "      if image_noise <2:\n",
        "        image = np.random.random((dim,dim,3))*0+255\n",
        "      elif image_noise == 2:\n",
        "        image = np.random.random((dim,dim,3))*0\n",
        "      else:\n",
        "        image = fil()\n",
        "        image = cv2.resize(image, (dim,dim),interpolation = cv2.INTER_NEAREST) \n",
        "        image = image[:,:,0:3]\n",
        "       \n",
        "      if l == 1:\n",
        "        for j in range(random.randint(1,20)):\n",
        "\n",
        "          if image_noise >1:\n",
        "            type_of_noise = random.randint(0,len(noise_exclusive)-1)\n",
        "          else:\n",
        "            type_of_noise = random.randint(0,len(noises)-1)\n",
        "            \n",
        "          r,g,b = cv2.split(image)\n",
        "          r = noisy(noises[type_of_noise],r)\n",
        "          g = noisy(noises[type_of_noise],g)\n",
        "          b = noisy(noises[type_of_noise],b)\n",
        "          image = cv2.merge((r,g,b))\n",
        "      for j in range(random.randint(5,20)):\n",
        "        size_square = 20   #The value is to be between 1 and 30\n",
        "        x = np.random.randint(0,dim - 1)\n",
        "        y = np.random.randint(0,dim - 1)\n",
        "        max_height_x = random.randint(0,dim - size_square)\n",
        "        max_height_y = random.randint(0,dim - size_square)\n",
        "        r,g,b = cv2.split(image)\n",
        "        r = random_square(r,x,y,max_height_x,max_height_y)\n",
        "        x = np.random.randint(0,dim - 1)\n",
        "        y = np.random.randint(0,dim - 1)\n",
        "        max_height_x = random.randint(0,dim - size_square)\n",
        "        max_height_y = random.randint(0,dim - size_square)\n",
        "        g = random_square(g,x,y,max_height_x,max_height_y)\n",
        "        x = np.random.randint(0,dim - 1)\n",
        "        y = np.random.randint(0,dim - 1)\n",
        "        max_height_x = random.randint(0,dim - size_square)\n",
        "        max_height_y = random.randint(0,dim - size_square)\n",
        "        b = random_square(b,x,y,max_height_x,max_height_y)\n",
        "        image = cv2.merge((r,g,b))  \n",
        "      attack_data[k]  =   image\n",
        "      # print(k)\n",
        "      k = k+1\n",
        "   \n",
        "      if  k == 100000  :\n",
        "        if  FLAG ==0:\n",
        "          FLAG = 1\n",
        "          y_pred =model.predict(attack_data)\n",
        "\n",
        "          attack_data_final,attack_y_final  = normalize_attack(attack_data,y_pred)\n",
        "          attack_y_max = np.argmax(attack_y_final,axis=-1)\n",
        "          k= 0\n",
        "          evalu_quar(attack_y_max)\n",
        "        else:\n",
        "          y_pred =model.predict(attack_data)\n",
        "\n",
        "          tmp_data,tmp_y  = normalize_attack(attack_data,y_pred)\n",
        "          attack_data_final = np.concatenate((attack_data_final,tmp_data),axis=0)\n",
        "          k=0\n",
        "          attack_y_final =np.concatenate((attack_y_final, tmp_y), axis=0)\n",
        "\n",
        "    if number_attack_vector >100000 :\n",
        "\n",
        "     return attack_data_final, attack_y_final\n",
        "    else:\n",
        "      y_pred =model.predict(attack_data)\n",
        "\n",
        "      return attack_data,y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TUXHsUH6EI1"
      },
      "source": [
        "\n",
        "np.random.seed(100)\n",
        "\n",
        "seta = np.random.randint(0,1000000,size=(10,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkVrz22H6LsQ"
      },
      "source": [
        "np.random.seed(100)\n",
        "\n",
        "seta = np.random.randint(0,1000000,size=(10,))\n",
        "std = []\n",
        "\n",
        "for i in tqdm(seta):\n",
        "  np.random.seed(i)\n",
        "  attack_data, y_pred = query(1000)\n",
        "  attack_y_max = np.argmax(y_pred,axis=-1)\n",
        "  if len(np.unique(attack_y_max))>8:\n",
        "    k = np.std(attack_y_max)\n",
        "    std.append(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfGP8ngb6LvT"
      },
      "source": [
        "np.where(std == np.max(std))[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRoqrBbb6Lxr"
      },
      "source": [
        "\n",
        "np.random.seed(seta[np.where(std == np.max(std))[0][0]])\n",
        "\n",
        "attack_data,attack_y = query(1000000)\n",
        "\n",
        "attack_y_max = np.argmax(attack_y,axis=-1)\n",
        "evalu_quar(attack_y_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYhyuITh6L0W"
      },
      "source": [
        "np.save(\"attack_data_10000000.npy\",attack_data)\n",
        "\n",
        "np.save(\"attack_y_1000000.npy\",attack_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMiBN1d6L3C"
      },
      "source": [
        "attack_data1,attack_y1 = normalize_attack(attack_data,attack_y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVKlmfuC6L5a"
      },
      "source": [
        "attack_y_max = np.argmax(attack_y1,axis=-1)\n",
        "evalu_quar(attack_y_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqh8DYD96L8G"
      },
      "source": [
        "print(y_pred.shape)\n",
        "print(attack_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP4C9AtN6L-w"
      },
      "source": [
        "for i in range(10):\n",
        "    plt.imshow(attack_data[i*35,:,:])\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsV_6I7h6bw4"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHDR8_fN6b4K"
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',input_shape = (32,32,3),include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "# x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "x=Dense(256,activation='relu')(x) #dense layer 3\n",
        "preds =Dense(10,activation='softmax')(x) #final layer with softmax activation\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "for layer in base_model.layers:\n",
        "\tlayer.trainable = False\n",
        "opt = optimizers.Adam(0.001)\n",
        "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLmvwliu6b63"
      },
      "source": [
        "attack_y_max  =  keras.utils.to_categorical(attack_y_max,10)\n",
        "file_path =\"cifar_attack.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]\n",
        "model.fit(attack_data, attack_y_max, epochs=200, verbose=1, callbacks=callbacks_list, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRv6qbMX6b9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilKq_7vJ6b_l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrFgvMrU6cCt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54uZ5b-e6cFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVQIe1OL6cQW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}